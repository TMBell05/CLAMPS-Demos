{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92b7c350",
   "metadata": {},
   "source": [
    "# CLAMPS Lidar Vertical Stare Tutorial\n",
    "\n",
    "This tutorial will show you how to work with vertical stare data from the Halo Photonics Streamline lidars with the CLAMPS systems at OU and NSSL.\n",
    "\n",
    "\n",
    "## Getting Data\n",
    "CLAMPS data is stored on a THREDDS server (https://data.nssl.noaa.gov/thredds/catalog/FRDD/CLAMPS/catalog.html). We are going to use Siphon to grab the data from the server. If you use Anaconda, Siphon can be download by running\n",
    "```\n",
    "conda install -c conda-forge siphon\n",
    "```\n",
    "on the command line. If you use pip the command would be\n",
    "```\n",
    "pip install siphon\n",
    "```\n",
    "\n",
    "## Vertical Stares\n",
    "While a vertical stare may be simple, it can provide valuable information. These stares can observe subtle vertical motion associated with features such as gravity waves and bores or when run constantly over a long enough period of time they can be used to retrieve profiles of vertical velocity variance.'\n",
    "\n",
    "We are going to work with vertical stare data from the CLAMPS 1 lidar during the BLISS-FUL campaign on June 20, 2021. Let's first get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from siphon.catalog import TDSCatalog\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Catalog for the CLAMPS1 ingested Stare data\n",
    "catURL = \"https://data.nssl.noaa.gov/thredds/catalog/FRDD/CLAMPS/clamps/clamps1/ingested/clampsdlfpC1.b1/catalog.xml\"\n",
    "\n",
    "# Open the catalog\n",
    "cat = TDSCatalog(catURL)\n",
    "\n",
    "# Date we want to grab\n",
    "dt = datetime(2021, 6, 20)\n",
    "\n",
    "# Get the dates for all the netCDF datasets (have to do it this way because file names can be messed up)\n",
    "nc_dates = []\n",
    "for ds in cat.datasets:\n",
    "    if '.cdf' in ds:\n",
    "        try:\n",
    "            nc_dates.append(datetime.strptime(ds, \"clampsdlfpC1.b1.%Y%m%d.%H%M%S.cdf\"))\n",
    "        except:\n",
    "            nc_dates.append(datetime(2100,1,1))\n",
    "            print('This file name is messed up: ' + ds)\n",
    "\n",
    "nc_dates = np.array(nc_dates)\n",
    "\n",
    "# Find the index of the date we want\n",
    "ind = np.argmin(np.abs(dt - nc_dates))\n",
    "\n",
    "# Get the dataset\n",
    "ds = cat.datasets[ind]\n",
    "\n",
    "# Download the dataset we identified to our current working directory\n",
    "ds.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd26610",
   "metadata": {},
   "source": [
    "The data is now downloaded to your working directory. It is a netCDF file so we are going to open it with the netCDF4 package and look at the variables in the netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d3564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "nc = Dataset(ds,'r')\n",
    "\n",
    "print(nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea8fe1",
   "metadata": {},
   "source": [
    "Let's read in the velocity, backscatter, intensity, cbh, height, and hour fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b73a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = nc.variables['hour'][:]\n",
    "bsc = nc.variables['backscatter'][:]\n",
    "intensity = nc.variables['intensity'][:]\n",
    "velocity = nc.variables['velocity'][:]\n",
    "cbh = nc.variables['cbh'][:]\n",
    "height = nc.variables['height'][:]\n",
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38374b3",
   "metadata": {},
   "source": [
    "Now we are going to remove data below a set intensity value and then plot the backscatter, cloud based height, and velocity fields in time-height plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "\n",
    "# Use the intensity to threshold the data\n",
    "foo = np.where(intensity < 1.007)\n",
    "\n",
    "bsc[foo] = np.nan\n",
    "velocity[foo] = np.nan\n",
    "\n",
    "# We need to calculate height from the range values\n",
    "\n",
    "fig, (backscatter, vert) =  plt.subplots(2, sharex=True)\n",
    "fig.set_figheight(10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "# There are so many points in this plot that it will wipe out your RAM if you try to plot all of it\n",
    "# so we are only plotting up to 2 km\n",
    "\n",
    "foo = np.where(height <= 2)[0]\n",
    "\n",
    "a = backscatter.pcolormesh(hour,height[foo],np.log10(bsc[:,foo].T),cmap ='turbo', vmin=-7, vmax=-3, shading = 'auto')\n",
    "backscatter.scatter(hour,cbh,color='k')\n",
    "b = vert.pcolormesh(hour,height[foo],velocity[:,foo].T,cmap = 'seismic', vmin=-3, vmax=3, shading = 'auto')\n",
    "\n",
    "cb = plt.colorbar(a, ax=backscatter)\n",
    "cb.set_label('[1/ms]')\n",
    "\n",
    "cb = plt.colorbar(b, ax=vert)\n",
    "cb.set_label('[m/s]')\n",
    "    \n",
    "backscatter.set_ylim([0,2])\n",
    "vert.set_ylim([0,2])\n",
    "\n",
    "backscatter.set_ylabel('Height [km]')\n",
    "vert.set_ylabel('Height [km]')\n",
    "vert.set_xlabel('Hour [UTC]')\n",
    "\n",
    "backscatter.set_title('Backscatter')\n",
    "vert.set_title('Vertical Velocity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294b6eb",
   "metadata": {},
   "source": [
    "Lets calculate 15 minute vertical velocity variance from this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_time = np.arange(7.5,1441,15)/60\n",
    "w_var = np.ones((len(avg_time),len(height)))*np.nan\n",
    "\n",
    "# Loop over avg_time can calculate the variance in that 30 minute period\n",
    "for i in range(len(avg_time)):\n",
    "    foo = np.where(((hour >= avg_time[i]-0.25) & (hour < avg_time[i]+0.25)))[0]\n",
    "    w_var[i,:] = np.nanvar(velocity[foo,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb93cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.where(height <= 2)[0]\n",
    "\n",
    "# And now plot that vertical velocity variance\n",
    "fig, (var_plot) =  plt.subplots(1)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "a = var_plot.pcolormesh(avg_time,height[foo], w_var[:,foo].T,cmap ='viridis',vmin=0, vmax=2, shading = 'auto')\n",
    "\n",
    "cb = plt.colorbar(a, ax=var_plot)\n",
    "cb.set_label('[$m^2/s^2$]')\n",
    "\n",
    "var_plot.set_ylim([0,2])\n",
    "\n",
    "var_plot.set_ylabel('Height [km]')\n",
    "var_plot.set_xlabel('Hour [UTC]')\n",
    "\n",
    "var_plot.set_title('Vertical Velocity Variance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf7a90a",
   "metadata": {},
   "source": [
    "Note: this vertical velocity variance calculation is fine when just trying to get an idea for what is happening for a particular day. If you want to produce publication quality vertical velocity variance you will have to use do a Lenshow correction to the data to remove noise from the lidar from the the variance. This correction is a little beyond this basic lidar training, but I can show you how to do it if you need it. My hot take on this topic is that lidar technology has advanced significantly is the 22 years since the Lenshow paper was written and the noise in the measurements is much less than before, making the correction less important to do. This is especially true when you are sampling with a large number of rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
